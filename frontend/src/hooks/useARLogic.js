/**
 * AR Logic Hook
 * Handles all AR initialization and management logic
 */
// projcet is ready yeaheeeee

import { useRef, useCallback, useEffect } from 'react';
import { 
  validateImageForMindAR, 
  processImageForAR, 
  fetchMindFile, 
  base64ToUint8Array, 
  isValidMindBuffer, 
  throttle,
  isMobileDevice,
  getCameraConstraints,
  getMindARFacingMode
} from '../utils/arUtils';
import { shouldTrackAnalytics, markAnalyticsFailed } from '../utils/analyticsDeduplication';

export const useARLogic = ({
  librariesLoaded,
  projectData,
  userId,
  projectId,
  isInitialized,
  isScanning,
  videoPlaying,
  videoMuted,
  targetDetected,
  setError,
  setCameraActive,
  setArReady,
  setTargetDetected,
  setVideoPlaying,
  setVideoMuted,
  setIsInitialized,
  setIsScanning,
  addDebugMessage,
  resetARState,
  trackAnalytics,  // Add analytics tracking
  setCameraPermissionRequired,
  setCameraPermissionBlocked,
  setCameraPermissionDismissed
}) => {
  // Ensure setVideoMuted is available
  const safeSetVideoMuted = setVideoMuted || (() => {
    console.warn('setVideoMuted not provided');
  });
  // Refs
  const containerRef = useRef(null);
  const videoRef = useRef(null);
  const mindarRef = useRef(null);
  const sceneRef = useRef(null);
  const rendererRef = useRef(null);
  const cameraRef = useRef(null);
  const anchorRef = useRef(null);
  const videoMeshRef = useRef(null);
  const blobURLRef = useRef(null); // Store blob URL for cleanup
  const savedVideoTimeRef = useRef(0); // Store video time when target is lost for resume
  const videoViewTrackedRef = useRef(false); // Track if video view has been counted
  const isResuming = useRef(false); // Prevent multiple simultaneous resume attempts

  // Throttled state updates
  const throttledSetTargetDetected = useCallback(
    throttle((value) => setTargetDetected(value), 100),
    [setTargetDetected]
  );

  const throttledSetVideoPlaying = useCallback(
    throttle((value) => setVideoPlaying(value), 200),
    [setVideoPlaying]
  );

  // Setup video mesh
  const setupVideo = useCallback(async (anchor) => {
    if (!projectData?.videoUrl || !window.THREE) return;

    try {
      addDebugMessage('üé¨ Setting up video...', 'info');

      const video = document.createElement('video');
      video.src = projectData.videoUrl;
      video.muted = true;
      video.loop = false; // Don't loop - preserve video time for resume functionality
      video.playsInline = true;
      video.crossOrigin = 'anonymous';
      video.preload = 'auto'; // Changed from 'metadata' to 'auto' for faster loading
      video.controls = false;
      video.autoplay = false; // Don't autoplay - wait for target detection
      video.preservesPitch = false; // Better performance on mobile
      
      // Mobile-specific attributes for iOS and Android
      video.setAttribute('webkit-playsinline', 'true');
      video.setAttribute('playsinline', 'true');
      video.setAttribute('muted', 'true');
      video.setAttribute('x-webkit-airplay', 'allow');
      
      // Additional mobile optimization
      video.style.objectFit = 'contain'; // Ensure video fits within the mesh
      
      videoRef.current = video;
      
      addDebugMessage('üì± Video element created with mobile optimizations', 'info');
      
      // Wait for video to be ready before creating texture
      await new Promise((resolve, reject) => {
        const timeout = setTimeout(() => {
          reject(new Error('Video loading timeout'));
        }, 10000);

        video.addEventListener('loadedmetadata', () => {
          clearTimeout(timeout);
          addDebugMessage('‚úÖ Video metadata loaded', 'info');
          addDebugMessage(`üìπ Video dimensions: ${video.videoWidth}x${video.videoHeight}`, 'info');

          // Set initial muted state based on current state
          video.muted = videoMuted !== false;
          resolve();
        }, { once: true });
        
        video.addEventListener('canplay', () => {
          addDebugMessage('‚úÖ Video ready to play', 'info');
        }, { once: true });
        
        video.load(); // Start loading
      });
      
      // ‚úÖ CRITICAL: Pre-load video but DON'T play yet
      // We'll start playback when target is detected
      // On mobile, we need to "prime" the video by attempting to play then pause
      try {
        await video.play();
        video.pause();
        // Don't reset currentTime to 0 - let it stay at 0 naturally
        addDebugMessage('‚úÖ Video primed and ready (will play on target detection)', 'success');
      } catch (playError) {
        addDebugMessage(`‚ö†Ô∏è Video priming failed: ${playError.message}`, 'warning');
        addDebugMessage('üí° Video may require user interaction to play', 'info');
      }

      // ‚úÖ CRITICAL: Create HIGH QUALITY texture and material
      const texture = new window.THREE.VideoTexture(video);
      
      // High-quality texture settings for crisp video display
      texture.minFilter = window.THREE.LinearFilter;
      texture.magFilter = window.THREE.LinearFilter;
      texture.format = window.THREE.RGBAFormat;
      texture.generateMipmaps = false; // Disable mipmaps for videos (better performance and quality)
      texture.needsUpdate = true;
      
      // Enable anisotropic filtering for better quality at angles (if supported)
      const renderer = rendererRef.current;
      if (renderer) {
        const maxAnisotropy = renderer.capabilities.getMaxAnisotropy();
        texture.anisotropy = Math.min(16, maxAnisotropy); // Use max quality but cap at 16
        addDebugMessage(`üé® Video anisotropic filtering: ${texture.anisotropy}x`, 'info');
      }
      
      // Set correct color space for proper color reproduction
      texture.colorSpace = window.THREE.SRGBColorSpace || window.THREE.sRGBEncoding;

      // ‚úÖ DYNAMIC SIZING: Calculate dimensions to match the detected target exactly
      // The video should overlay perfectly on the physical printed design
      
      // Get the video aspect ratio
      const videoAspect = video.videoWidth / video.videoHeight;
      
      // Get the target (design) aspect ratio
      const designAspect = projectData.designDimensions 
        ? projectData.designDimensions.width / projectData.designDimensions.height 
        : 1;
      
      addDebugMessage(`üìê Video aspect: ${videoAspect.toFixed(2)}, Design aspect: ${designAspect.toFixed(2)}`, 'info');
      
      // MindAR targets are normalized to fit within a 1x1 unit square
      // We need to size the video plane to match this 1:1 with the target
      let planeWidth, planeHeight;
      
      // Option 1: Fit video to cover entire target (may crop video)
      // Option 2: Fit video to fit within target (may show borders)
      // We'll use "cover" behavior - video fills the entire target
      
      if (videoAspect > designAspect) {
        // Video is wider than target - fit height, crop width
        planeHeight = 1;
        planeWidth = videoAspect / designAspect;
      } else {
        // Video is taller than target - fit width, crop height
        planeWidth = 1;
        planeHeight = designAspect / videoAspect;
      }
      
      const geometry = new window.THREE.PlaneGeometry(planeWidth, planeHeight);
      
      // ‚úÖ Create material with proper transparency handling
      const material = new window.THREE.MeshBasicMaterial({ 
        map: texture,
        transparent: false,
        side: window.THREE.FrontSide
      });

      const videoMesh = new window.THREE.Mesh(geometry, material);
      
      // Position at the center of the anchor (target)
      videoMesh.position.set(0, 0, 0);
      videoMesh.rotation.x = 0;
      
      // ‚úÖ NO SCALING - Video plane is already sized to match the target (1:1)
      // The anchor itself is positioned and scaled by MindAR to match the detected target
      videoMesh.scale.set(1, 1, 1);
      
      addDebugMessage(`üìê Video plane size: ${planeWidth.toFixed(2)} x ${planeHeight.toFixed(2)} (matches target 1:1)`, 'info');
      
      videoMeshRef.current = videoMesh;
      anchor.group.add(videoMesh);
      
      // Initially hidden - will be shown in animation loop when anchor.visible
      videoMesh.visible = false;
      
      addDebugMessage('üé¨ Video mesh added to anchor (1:1 scale with detected target)', 'info');
      addDebugMessage('üìè Video will overlay exactly on the physical printed design', 'success');

      // Video event listeners
      video.addEventListener('loadedmetadata', () => {
        addDebugMessage('‚úÖ Video metadata loaded', 'success');
        addDebugMessage(`üìπ Video dimensions: ${video.videoWidth}x${video.videoHeight}`, 'info');
      });

      video.addEventListener('canplay', () => {
        addDebugMessage('‚úÖ Video ready to play', 'success');
      });

      video.addEventListener('play', () => {
        setVideoPlaying(true);
        addDebugMessage('‚ñ∂Ô∏è Video started playing', 'success');
      });

      video.addEventListener('pause', () => {
        setVideoPlaying(false);
        addDebugMessage('‚è∏Ô∏è Video paused', 'info');
      });

      video.addEventListener('ended', () => {
        // When video ends, restart from beginning (manual loop for better control)
        video.currentTime = 0;
        savedVideoTimeRef.current = 0;
        setVideoPlaying(false);
        addDebugMessage('üîÑ Video ended, restarting...', 'info');
        // Video will auto-play if target is still visible (handled by animation loop)
      });

      addDebugMessage('‚úÖ Video mesh created successfully', 'success');

    } catch (error) {
      addDebugMessage(`‚ùå Video setup failed: ${error.message}`, 'error');
    }
  }, [projectData, addDebugMessage, setVideoPlaying]);

  // Initialize MindAR
  const initializeMindAR = useCallback(async (retryCount = 0, maxRetries = 3) => {
    const retryDelay = Math.min(1000 * Math.pow(2, retryCount), 5000);
    
    // Prevent multiple initializations
    if (mindarRef.current) {
      addDebugMessage('‚ö†Ô∏è MindAR already initialized, skipping...', 'warning');
      return true;
    }
    
    // Check if we're already in the process of initializing
    if (isInitialized) {
      addDebugMessage('‚ö†Ô∏è AR already initialized, skipping...', 'warning');
      return true;
    }
    
    addDebugMessage(`üîç Checking container element (attempt ${retryCount + 1}/${maxRetries + 1})...`, 'info');
    
    if (!containerRef.current || containerRef.current.offsetWidth === 0 || containerRef.current.offsetHeight === 0) {
      if (retryCount < maxRetries) {
        addDebugMessage(`‚ö†Ô∏è Container not ready yet, retrying in ${retryDelay}ms... (${retryCount + 1}/${maxRetries})`, 'warning');
        
        setTimeout(() => {
          addDebugMessage(`üîÑ Retrying MindAR initialization (attempt ${retryCount + 2})...`, 'info');
          initializeMindAR(retryCount + 1, maxRetries);
        }, retryDelay);
        return false;
      } else {
        addDebugMessage('‚ùå Container failed to initialize after maximum retries', 'error');
        setError('AR container could not be initialized. Please refresh the page and try again.');
        return false;
      }
    }
    
    if (!librariesLoaded || !projectData) {
      addDebugMessage('‚ùå MindAR init failed: Missing requirements', 'error');
      return false;
    }
    
    addDebugMessage(`‚úÖ Container ready: ${containerRef.current.offsetWidth}x${containerRef.current.offsetHeight}`, 'success');
    
    // Ensure container has minimum dimensions
    if (containerRef.current.offsetWidth < 100 || containerRef.current.offsetHeight < 100) {
      addDebugMessage('‚ö†Ô∏è Container too small, forcing minimum dimensions', 'warning');
      containerRef.current.style.width = '100%';
      containerRef.current.style.height = '100%';
      containerRef.current.style.minWidth = '320px';
      containerRef.current.style.minHeight = '240px';
    }

    try {
      addDebugMessage('üöÄ Initializing MindAR...', 'info');

      let targetUrl = projectData.designUrl;
      let targetType = 'image file';
      let mindBuffer = null;
      
      // CRITICAL: Check for .mind file FIRST - but allow fallback to composite image if .mind file unavailable
      // Replicate upload page logic: prefer .mind file, but allow composite image fallback
      if (projectData.mindTargetUrl) {
        addDebugMessage('üéØ Found .mind file URL - validating before use...', 'info');
        
        // Try to fetch and validate the .mind file
        try {
          const testBuffer = await fetchMindFile(projectData.mindTargetUrl, addDebugMessage);
          // If we get here, the .mind file is valid binary format
          targetUrl = projectData.mindTargetUrl;
          targetType = '.mind file';
          addDebugMessage('‚úÖ Valid .mind file found - using for AR tracking (best performance)', 'success');
        } catch (mindValidationError) {
          // .mind file is invalid (likely JSON fallback) - fall back to composite image
          addDebugMessage('‚ö†Ô∏è .mind file validation failed - file appears to be JSON fallback, not binary', 'warning');
          addDebugMessage(`üîç Validation error: ${mindValidationError.message}`, 'info');
          addDebugMessage('üîÑ Falling back to composite image for AR tracking', 'info');
          
          if (projectData.compositeDesignUrl) {
            targetUrl = projectData.compositeDesignUrl;
            targetType = 'image file';
            addDebugMessage('‚úÖ Using composite image as fallback (may have reduced tracking performance)', 'warning');
          } else if (projectData.designUrl) {
            targetUrl = projectData.designUrl;
            targetType = 'image file';
            addDebugMessage('‚úÖ Using design image as fallback (may have reduced tracking performance)', 'warning');
          } else {
            addDebugMessage('‚ùå No valid .mind file and no composite/design image available', 'error');
            setError('AR tracking requires a valid .mind file or composite image. Please ensure your campaign has a composite design.');
            return false;
          }
        }
      } else {
        // No .mind file URL - use composite image or design image as fallback
        if (projectData.compositeDesignUrl) {
          addDebugMessage('‚ö†Ô∏è No .mind file available - using composite image for AR tracking', 'warning');
          addDebugMessage('üí° .mind files provide better tracking performance, but composite images can work as fallback', 'info');
          targetUrl = projectData.compositeDesignUrl;
          targetType = 'image file';
        } else if (projectData.designUrl) {
          addDebugMessage('‚ö†Ô∏è No .mind file or composite - using design image for AR tracking', 'warning');
          addDebugMessage('üí° This may have reduced tracking performance', 'info');
          targetUrl = projectData.designUrl;
          targetType = 'image file';
        } else {
          addDebugMessage('‚ùå No .mind file, composite design, or design image available', 'error');
          addDebugMessage('üí° Users need to scan the composite image (design + QR code)', 'info');
          addDebugMessage('üîß Please generate composite design', 'info');
          setError('No target image available for AR tracking. Please ensure a composite design is available.');
          return false;
        }
      }

      addDebugMessage(`üéØ Using target: ${targetType}`, 'info');
      addDebugMessage(`üîó Target URL: ${targetUrl}`, 'info');
      
      if (targetType === 'image file') {
        try {
          await validateImageForMindAR(targetUrl, addDebugMessage);
          const processedUrl = await processImageForAR(targetUrl, addDebugMessage);
          targetUrl = processedUrl;
          addDebugMessage(`‚úÖ Using processed image URL: ${processedUrl.substring(0, 50)}...`, 'success');
        } catch (validationError) {
          addDebugMessage(`‚ùå Image validation failed: ${validationError.message}`, 'error');
          addDebugMessage('üîÑ Attempting to use original URL as fallback...', 'warning');
          // Don't throw error, try with original URL
        }
      } else if (targetType === '.mind file') {
        addDebugMessage('üéØ Using .mind file target', 'info');
        try {
          // Fetch .mind file as binary buffer (already validated above, but fetch again for use)
          mindBuffer = await fetchMindFile(targetUrl, addDebugMessage);
          addDebugMessage('‚úÖ .mind file loaded successfully', 'success');
        } catch (mindError) {
          // This should not happen since we validated above, but handle it anyway
          addDebugMessage(`‚ùå Failed to load .mind file: ${mindError.message}`, 'error');
          throw new Error(`MindAR .mind file failed to load: ${mindError.message}`);
        }
      }

      // Create MindAR instance
      addDebugMessage('üîß Creating MindAR instance...', 'info');
      
      const mindarConfig = {
        container: containerRef.current,
        maxTrack: 1,
        filterMinCF: 0.00005,
        filterBeta: 0.002,
        warmupTolerance: 20,
        missTolerance: 20,
        facingMode: getMindARFacingMode(), // Back camera on mobile, front on desktop
        resolution: { 
          width: Math.min(containerRef.current.offsetWidth, 640),
          height: Math.min(containerRef.current.offsetHeight, 480) 
        },
        // Ensure canvas is visible and properly positioned
        uiScanning: false, // Disable default UI scanning overlay
        uiLoading: false,  // Disable default UI loading overlay
        uiError: false     // Disable default UI error overlay
      };
      
      addDebugMessage(`üîß MindAR facing mode: ${mindarConfig.facingMode} (mobile: ${isMobileDevice()})`, 'info');

      // Add specific configuration based on target type
      if (targetType === '.mind file' && mindBuffer) {
        // ‚úÖ Create a Blob URL from the binary buffer
        // MindAR expects a URL, not raw binary data
        const blob = new Blob([mindBuffer], { type: 'application/octet-stream' });
        const blobURL = URL.createObjectURL(blob);
        blobURLRef.current = blobURL; // Store for cleanup
        mindarConfig.imageTargetSrc = blobURL;
        addDebugMessage('üîß Created Blob URL for .mind file', 'info');
        addDebugMessage(`üìç Blob URL: ${blobURL.substring(0, 50)}...`, 'info');
      } else {
        // For image files, we need to ensure MindAR processes them correctly
        // CRITICAL: When using an image file (not .mind), we must ensure MindAR knows it's an image
        // and doesn't try to process it as a .mind file buffer
        
        // Normalize the image URL to ensure it's clearly an image
        let imageUrl = targetUrl;
        
        // If the URL might be confused with a .mind file, ensure it's clearly an image
        if (imageUrl.includes('/raw/upload/') && !imageUrl.match(/\.(png|jpg|jpeg|webp)$/i)) {
          // This might be a .mind file URL - don't use it as an image
          addDebugMessage('‚ö†Ô∏è Warning: URL appears to be a .mind file, not an image', 'warning');
          throw new Error('Cannot use .mind file URL as image. Please use compositeDesignUrl instead.');
        }
        
        // CRITICAL: Convert image URL to data URL to ensure MindAR treats it as an image, not a .mind file
        // This prevents MindAR from trying to use addImageTargetsFromBuffer on an image URL
        addDebugMessage('üîÑ Converting image URL to data URL for safe MindAR processing...', 'info');
        try {
          // Fetch image and convert to data URL
          const imageResponse = await fetch(imageUrl);
          if (!imageResponse.ok) {
            throw new Error(`Failed to fetch image: ${imageResponse.status} ${imageResponse.statusText}`);
          }
          const imageBlob = await imageResponse.blob();
          
          // Validate it's actually an image
          if (!imageBlob.type.startsWith('image/')) {
            throw new Error(`URL does not point to an image: ${imageBlob.type}`);
          }
          
          // Convert to data URL
          const dataUrl = await new Promise((resolve, reject) => {
            const reader = new FileReader();
            reader.onloadend = () => resolve(reader.result);
            reader.onerror = reject;
            reader.readAsDataURL(imageBlob);
          });
          
          mindarConfig.imageTargetSrc = dataUrl;
          addDebugMessage('‚úÖ Image converted to data URL - MindAR will process as image', 'success');
          addDebugMessage(`üìä Image type: ${imageBlob.type}, size: ${imageBlob.size} bytes`, 'info');
        } catch (conversionError) {
          addDebugMessage(`‚ö†Ô∏è Failed to convert image to data URL: ${conversionError.message}`, 'warning');
          addDebugMessage('üîÑ Falling back to direct image URL (may cause issues)', 'warning');
          
          // Fallback: Ensure Cloudinary image URLs have proper image format parameters
          if (imageUrl.includes('cloudinary.com') && !imageUrl.includes('f_')) {
            const separator = imageUrl.includes('?') ? '&' : '?';
            imageUrl = `${imageUrl}${separator}f_png`; // Force PNG format
            addDebugMessage('üîß Added format parameter to Cloudinary URL', 'info');
          }
          
          mindarConfig.imageTargetSrc = imageUrl;
          addDebugMessage('üîß Using image URL directly for MindAR', 'info');
          addDebugMessage('‚ö†Ô∏è Note: Image files are processed by MindAR internally (may have reduced performance)', 'warning');
        }
        
        // Add specific image processing hints
        if (imageUrl.includes('.png') || imageUrl.includes('f_png') || imageUrl.includes('format=png')) {
          addDebugMessage('üñºÔ∏è Detected PNG image format - MindAR will handle conversion', 'info');
        } else if (imageUrl.includes('.jpg') || imageUrl.includes('.jpeg') || imageUrl.includes('f_jpg')) {
          addDebugMessage('üñºÔ∏è Detected JPEG image format - MindAR will handle conversion', 'info');
        }
        
        // Validate the image before passing to MindAR
        try {
          addDebugMessage('üîß Validating image for MindAR compatibility...', 'info');
          
          // Create a temporary image element to validate the image
          const testImg = new Image();
          testImg.crossOrigin = 'anonymous';
          
          await new Promise((resolve, reject) => {
            const timeout = setTimeout(() => {
              reject(new Error('Image validation timeout'));
            }, 10000);
            
            testImg.onload = () => {
              clearTimeout(timeout);
              addDebugMessage(`‚úÖ Image validation successful: ${testImg.naturalWidth}x${testImg.naturalHeight}`, 'success');
              resolve();
            };
            testImg.onerror = () => {
              clearTimeout(timeout);
              reject(new Error('Image validation failed'));
            };
            testImg.src = imageUrl;
          });
          
          addDebugMessage('üîß Image pre-validation completed', 'success');
        } catch (imgError) {
          addDebugMessage(`‚ö†Ô∏è Image pre-validation failed: ${imgError.message}`, 'warning');
          addDebugMessage('üîÑ Proceeding with original URL...', 'info');
        }
      }

      
      addDebugMessage(`üîß MindAR config: container=${mindarConfig.container ? 'ready' : 'missing'}, imageTarget=${mindarConfig.imageTargetSrc ? 'set' : 'missing'}`, 'info');
      addDebugMessage(`üîß Target URL type: ${typeof mindarConfig.imageTargetSrc}`, 'info');
      addDebugMessage(`üîß Target URL length: ${mindarConfig.imageTargetSrc ? mindarConfig.imageTargetSrc.length : 'N/A'}`, 'info');
      
      let mindar;
      try {
        // MindAR requires .mind files for image targets
        // If we only have an image file, we need to inform the user
        if (targetType === 'image file') {
          addDebugMessage('‚ö†Ô∏è Warning: Using image file without .mind file', 'warning');
          addDebugMessage('üí° MindAR will attempt to process the image, but a .mind file is recommended', 'info');
          addDebugMessage('üîß For best performance, generate a .mind file from the composite image', 'info');
        }
        
        // Create MindAR instance
        if (window.MindARThree && window.MindARThree.MindARThree) {
          mindar = new window.MindARThree.MindARThree(mindarConfig);
          mindarRef.current = mindar;
          addDebugMessage('‚úÖ MindAR instance created successfully', 'success');
        } else {
          throw new Error('MindARThree not available');
        }
      } catch (mindarError) {
        addDebugMessage(`‚ùå MindAR creation failed: ${mindarError.message}`, 'error');
        
        // If it's a buffer corruption error, handle it gracefully
        if (mindarError.message.includes('Extra') && mindarError.message.includes('byte')) {
          addDebugMessage('üîÑ Buffer corruption error detected', 'error');
          addDebugMessage(`üîç Error details: ${mindarError.message}`, 'info');
          
          // If we have a corrupted .mind file, try to regenerate it
          if (targetType === '.mind file') {
            addDebugMessage('‚ùå .mind file appears to be corrupted', 'error');
            addDebugMessage('üí° The .mind file may need to be regenerated', 'info');
            
            // If we have a composite image, suggest regenerating .mind file
            if (projectData.compositeDesignUrl) {
              addDebugMessage('üîÑ Attempting to use composite image as fallback...', 'warning');
              
              // Update target to use composite image instead
              targetUrl = projectData.compositeDesignUrl;
              targetType = 'image file';
              mindBuffer = null;
              mindarConfig.imageTargetSrc = targetUrl;
              
              // Try again with image
              try {
                mindar = new window.MindARThree.MindARThree(mindarConfig);
                mindarRef.current = mindar;
                addDebugMessage('‚úÖ MindAR instance created with fallback composite image', 'success');
              } catch (fallbackError) {
                addDebugMessage(`‚ùå Fallback also failed: ${fallbackError.message}`, 'error');
                throw new Error(
                  'AR tracking failed: .mind file is corrupted and image fallback also failed. ' +
                  'Please regenerate the .mind file by going back to Step 2: Save QR Position.'
                );
              }
            } else {
              throw new Error(
                'AR tracking failed: .mind file is corrupted. ' +
                'Please regenerate it by going back to Step 2: Save QR Position.'
              );
            }
          } else {
            // Image file buffer error - MindAR is trying to process image as buffer
            addDebugMessage('‚ùå Image processing error: MindAR requires a .mind file for reliable tracking', 'error');
            addDebugMessage('üí° Please generate a .mind file from your composite image', 'info');
            addDebugMessage('üîß Go back to Step 2: Save QR Position to generate the .mind file', 'info');
            
            throw new Error(
              'AR tracking requires a .mind file. ' +
              'Please go back to Step 2: Save QR Position to generate the required .mind file.'
            );
          }
        } else {
          throw new Error(`MindAR creation failed: ${mindarError.message}`);
        }
      }

      const { renderer, scene, camera } = mindar;
      
      if (!renderer || !scene || !camera) {
        throw new Error('MindAR objects are undefined');
      }
      
      // Fix Three.js deprecation warnings
      if (renderer.outputEncoding !== undefined) {
        delete renderer.outputEncoding;
      }
      renderer.outputColorSpace = window.THREE.SRGBColorSpace;
      
      // HIGH QUALITY renderer settings for crisp video display
      renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2)); // Use device pixel ratio but cap at 2x for performance
      renderer.sortObjects = true; // Enable object sorting for better transparency handling
      
      // Log renderer quality settings
      addDebugMessage(`üé® Renderer pixel ratio: ${renderer.getPixelRatio()}x`, 'info');
      addDebugMessage(`üé® Device pixel ratio: ${window.devicePixelRatio}x`, 'info');
      
      // Ensure we're using the same THREE instance as MindAR
      if (window.THREE && window.THREE.WebGLRenderer) {
        addDebugMessage('‚úÖ Using shared THREE.js instance', 'success');
      }
      
      rendererRef.current = renderer;
      sceneRef.current = scene;
      cameraRef.current = camera;
      
      addDebugMessage('‚úÖ MindAR objects validated and assigned', 'success');

      const anchor = mindar.addAnchor(0);
      anchorRef.current = anchor;
      
      // Configure anchor for better visibility
      anchor.group.visible = true;
      
      // DO NOT add ambient light - causes material.onBuild error with MindAR's Three.js

      if (projectData.videoUrl) {
        await setupVideo(anchor);
      }

      // Note: Using animation loop instead of onTargetFound/onTargetLost callbacks
      // The animation loop continuously checks anchor.visible (more reliable than callbacks)

      // Start MindAR
      addDebugMessage('üöÄ Starting MindAR...', 'info');
      
      // Request camera permission explicitly before starting MindAR
      try {
        addDebugMessage('üì∑ Requesting camera permission...', 'info');
        
        // Detect device type and get appropriate camera constraints
        const isMobile = isMobileDevice();
        addDebugMessage(`üì± Device type: ${isMobile ? 'Mobile' : 'Desktop'}`, 'info');
        
        // Get camera constraints - use exact for initial request
        const videoConstraints = getCameraConstraints(true);
        addDebugMessage(`üé• Camera constraints: ${JSON.stringify(videoConstraints)}`, 'info');
        
        const stream = await navigator.mediaDevices.getUserMedia({ 
          video: videoConstraints,
          audio: false
        });
        setCameraPermissionRequired?.(false);
        setCameraPermissionBlocked?.(false);
        setCameraPermissionDismissed?.(false);
        addDebugMessage('‚úÖ Camera permission granted', 'success');
        addDebugMessage(`üìπ Camera stream: ${stream.getVideoTracks().length} video track(s)`, 'info');
        
        // Log camera settings
        const videoTrack = stream.getVideoTracks()[0];
        const settings = videoTrack.getSettings();
        addDebugMessage(`üì∑ Camera settings: ${settings.width}x${settings.height}, facing: ${settings.facingMode || 'unknown'}`, 'info');
        
        // Stop the test stream as MindAR will handle the camera
        stream.getTracks().forEach(track => track.stop());
        addDebugMessage('‚úÖ Test stream stopped, MindAR will now initialize camera', 'success');
      } catch (permissionError) {
        addDebugMessage(`‚ùå Camera permission denied: ${permissionError.message}`, 'error');
        setCameraPermissionRequired?.(true);
        setError(null);
        const message = (permissionError?.message || '').toLowerCase();
        const dismissed = message.includes('dismissed');
        if (dismissed) {
          setCameraPermissionDismissed?.(true);
          setCameraPermissionBlocked?.(false);
        } else {
          setCameraPermissionBlocked?.(true);
          setCameraPermissionDismissed?.(false);
        }
        
        // If exact back camera fails on mobile, try with ideal constraint
        if (permissionError.name === 'OverconstrainedError') {
          addDebugMessage('üîÑ Retrying with relaxed constraints...', 'warning');
          try {
            // Use ideal constraints instead of exact
            const relaxedConstraints = getCameraConstraints(false);
            const stream = await navigator.mediaDevices.getUserMedia({ 
              video: relaxedConstraints,
              audio: false
            });
            stream.getTracks().forEach(track => track.stop());
            setCameraPermissionRequired?.(false);
            setCameraPermissionBlocked?.(false);
            setCameraPermissionDismissed?.(false);
            addDebugMessage('‚úÖ Camera permission granted with relaxed constraints', 'success');
          } catch (retryError) {
            addDebugMessage(`‚ùå Retry failed: ${retryError.message}`, 'error');
            setCameraPermissionRequired?.(true);
            setCameraPermissionBlocked?.(true);
            setCameraPermissionDismissed?.(false);
            return false;
          }
        } else {
          return false;
        }
      }
      
      try {
        // ‚úÖ CRITICAL: Start MindAR WITHOUT its auto-render loop
        // We'll set up our own loop that includes video control
        await mindar.start();
        addDebugMessage('‚úÖ MindAR started successfully', 'success');
        
        // ‚úÖ Stop MindAR's default animation loop (if it started one)
        // We'll create our own that includes both rendering and video control
        renderer.setAnimationLoop(null);
        addDebugMessage('üõë Stopped MindAR default loop', 'info');
        
        // ‚úÖ CRITICAL: Custom animation frame loop for video control
        // We use requestAnimationFrame instead of renderer.setAnimationLoop
        // to avoid conflicts with MindAR's internal rendering
        
        // Track previous state to avoid logging every frame
        let wasTargetVisible = false;
        let hasBeenPausedThisCycle = false; // Prevent double-pausing when target is lost
        
        const animateVideoControl = () => {
          const isTargetVisible = anchorRef.current && anchorRef.current.visible;
          
          // Reset pause flag when target becomes visible again
          if (isTargetVisible && !wasTargetVisible) {
            hasBeenPausedThisCycle = false;
          }
          
          // ‚úÖ CRITICAL: Update video texture every frame when video is playing
          // This ensures the video texture reflects the current video frame
          if (videoMeshRef.current && videoRef.current && !videoRef.current.paused) {
            if (videoMeshRef.current.material && videoMeshRef.current.material.map) {
              videoMeshRef.current.material.map.needsUpdate = true;
            }
          }
          
          if (isTargetVisible) {
            // ‚úÖ Target is detected - show video mesh AND play video
            // This matches the working code pattern exactly
            
            // Prepare video mesh (but don't show yet - will show after seek completes)
            if (videoMeshRef.current && !videoMeshRef.current.visible) {
              const timestamp = new Date().toLocaleTimeString();
              console.log(`üëÅÔ∏è [${timestamp}] Target detected, preparing video mesh`);
              console.log(`üìä [${timestamp}] Video mesh info:`, {
                visible: videoMeshRef.current.visible,
                position: videoMeshRef.current.position,
                scale: videoMeshRef.current.scale,
                hasTexture: !!videoMeshRef.current.material?.map,
                videoPlaying: videoRef.current && !videoRef.current.paused,
                videoCurrentTime: videoRef.current ? videoRef.current.currentTime : 0
              });
              // NOTE: Mesh visibility will be set by the seek/play logic below
              
              // Check if video element was destroyed and needs to be recreated
              if (!videoRef.current && videoMeshRef.current.material && videoMeshRef.current.material.map) {
                console.log(`üîß [${timestamp}] Video element lost, attempting to recover from texture...`);
                // Try to get the video element from the texture
                const texture = videoMeshRef.current.material.map;
                if (texture.image && texture.image.tagName === 'VIDEO') {
                  videoRef.current = texture.image;
                  console.log(`‚úÖ [${timestamp}] Recovered video element from texture`);
                  
                  // CRITICAL: Check if recovered video is playing when it shouldn't be
                  if (!videoRef.current.paused) {
                    // Video is playing but should be paused, save current time and pause it
                    savedVideoTimeRef.current = videoRef.current.currentTime;
                    videoRef.current.pause();
                    console.log(`‚è∏Ô∏è [${timestamp}] Recovered video was playing unexpectedly - paused at ${savedVideoTimeRef.current.toFixed(2)}s`);
                  }
                } else {
                  console.warn(`‚ö†Ô∏è [${timestamp}] WARNING: Could not recover video element!`);
                }
              }
              
              // Debug: Check video state immediately after target detection
              if (videoRef.current) {
                console.log(`üé¨ [${timestamp}] Video state at detection:`, {
                  paused: videoRef.current.paused,
                  currentTime: videoRef.current.currentTime.toFixed(2),
                  savedTime: savedVideoTimeRef.current.toFixed(2),
                  readyState: videoRef.current.readyState
                });
              } else {
                console.log(`‚ö†Ô∏è [${timestamp}] WARNING: videoRef.current is null/undefined and could not be recovered!`);
              }
            }
            
            // Play video if paused (resume from saved time)
            // CRITICAL: Prevent multiple simultaneous resume attempts
            if (videoRef.current && videoRef.current.paused && !isResuming.current) {
              isResuming.current = true; // Mark as resuming
              const timestamp = new Date().toLocaleTimeString();
              
              // Debug: Log video state before resume attempt
              console.log(`üîç [${timestamp}] Attempting to resume video:`, {
                paused: true,
                currentTime: videoRef.current.currentTime.toFixed(2),
                savedTime: savedVideoTimeRef.current.toFixed(2),
                readyState: videoRef.current.readyState,
                hasVideoRef: !!videoRef.current
              });
              
              // CRITICAL: Hide video mesh during entire resume process
              if (videoMeshRef.current) {
                videoMeshRef.current.visible = false;
                if (savedVideoTimeRef.current > 0.1) {
                  console.log(`üôà [${timestamp}] Hiding video mesh during resume to prevent frame 0 flash`);
                }
              }
              
              console.log(`‚ñ∂Ô∏è [${timestamp}] Starting video playback...`);
              
              // CRITICAL: On mobile, seeking a PAUSED video doesn't work reliably
              // Solution: Play FIRST, then seek WHILE PLAYING, then show mesh
              videoRef.current.play().then(() => {
                // Clear resume flag after successful play
                isResuming.current = false;
                const playTimestamp = new Date().toLocaleTimeString();
                console.log(`‚úÖ [${playTimestamp}] Video play() resolved, currentTime: ${videoRef.current.currentTime.toFixed(2)}s`);
                
                // CRITICAL: Wait for video decoder to stabilize BEFORE seeking
                // Mobile browsers need 100-200ms after play() before they accept seeks
                const targetTime = savedVideoTimeRef.current;
                // ALWAYS seek if targetTime > 0 to force texture update, even if currentTime is close
                if (targetTime > 0.5) { // Only skip seek if very beginning of video
                  console.log(`‚è≥ [${playTimestamp}] Waiting 150ms for decoder to stabilize before seeking to ${targetTime.toFixed(2)}s...`);
                  
                  // Wait for decoder to stabilize, THEN seek
                  setTimeout(() => {
                    if (!videoRef.current || videoRef.current.paused) {
                      console.warn(`‚ö†Ô∏è Video paused before seek could execute`);
                      return;
                    }
                    
                    const beforeSeek = videoRef.current.currentTime;
                    console.log(`‚è© [${new Date().toLocaleTimeString()}] Seeking from ${beforeSeek.toFixed(2)}s to ${targetTime.toFixed(2)}s (decoder ready)...`);
                    
                    try {
                      videoRef.current.currentTime = targetTime;
                    
                    // Poll until seek completes, then show mesh
                    let seekAttempts = 0;
                    const maxSeekAttempts = 30; // 600ms max wait
                    
                    const waitForSeek = () => {
                      seekAttempts++;
                      
                      if (!videoRef.current || !videoMeshRef.current) {
                        return; // Aborted
                      }
                      
                      const currentTime = videoRef.current.currentTime;
                      const diff = Math.abs(currentTime - targetTime);
                      const ts = new Date().toLocaleTimeString();
                      
                      if (diff < 0.5 || seekAttempts >= maxSeekAttempts) {
                        // Seek complete (or timeout), show mesh
                        const material = videoMeshRef.current.material;
                        if (material && material.map) {
                          for (let i = 0; i < 5; i++) {
                            material.map.needsUpdate = true;
                          }
                        }
                        videoMeshRef.current.visible = true;
                        
                        if (diff < 0.5) {
                          console.log(`üëÅÔ∏è [${ts}] Seek complete after ${seekAttempts * 20}ms - showing mesh at ${currentTime.toFixed(2)}s (target: ${targetTime.toFixed(2)}s)`);
                        } else {
                          console.warn(`‚ö†Ô∏è [${ts}] Seek timeout after ${seekAttempts * 20}ms - showing mesh anyway at ${currentTime.toFixed(2)}s (target: ${targetTime.toFixed(2)}s, diff: ${diff.toFixed(2)}s)`);
                        }
                      } else {
                        // Still seeking, check again
                        setTimeout(waitForSeek, 20);
                      }
                    };
                    
                      // Start checking after 50ms
                      setTimeout(waitForSeek, 50);
                      
                    } catch (seekError) {
                      console.error(`‚ùå [${new Date().toLocaleTimeString()}] Seek error:`, seekError);
                      // Show mesh anyway on error
                      if (videoMeshRef.current) {
                        videoMeshRef.current.visible = true;
                      }
                    }
                  }, 150); // Wait 150ms for decoder to stabilize
                } else {
                  // No seek needed, but WAIT for video to actually render correct frame
                  const expectedTime = targetTime;
                  console.log(`üëÅÔ∏è [${playTimestamp}] No seek needed (at ${videoRef.current.currentTime.toFixed(2)}s), but waiting for texture to render...`);
                  
                  // Poll to ensure video has moved past frame 0 and texture has updated
                  let renderAttempts = 0;
                  const maxRenderAttempts = 25; // 500ms max
                  
                  const waitForRender = () => {
                    renderAttempts++;
                    
                    if (!videoRef.current || !videoMeshRef.current) {
                      return; // Aborted
                    }
                    
                    const currentTime = videoRef.current.currentTime;
                    const ts = new Date().toLocaleTimeString();
                    
                    // For first play (expectedTime = 0), just show after short delay
                    // For resume, wait until currentTime is close to expected
                    const isCloseEnough = expectedTime === 0 ? 
                      renderAttempts >= 5 : // First play: just wait 100ms (5 * 20ms)
                      Math.abs(currentTime - expectedTime) < 1.0; // Resume: within 1 second
                    
                    if (isCloseEnough || renderAttempts >= maxRenderAttempts) {
                      const material = videoMeshRef.current.material;
                      if (material && material.map) {
                        for (let i = 0; i < 5; i++) {
                          material.map.needsUpdate = true;
                        }
                      }
                      videoMeshRef.current.visible = true;
                      console.log(`üëÅÔ∏è [${ts}] Texture ready after ${renderAttempts * 20}ms - showing mesh at ${currentTime.toFixed(2)}s (expected: ${expectedTime.toFixed(2)}s)`);
                    } else {
                      // Not ready yet, check again
                      setTimeout(waitForRender, 20);
                    }
                  };
                  
                  // Start checking after 50ms
                  setTimeout(waitForRender, 50);
                }
                
                // Track video view when video starts playing (using global deduplication)
                if (trackAnalytics && !videoViewTrackedRef.current) {
                  console.log('üé¨ Video playing, checking if should track...', {
                    userId: userId || projectId,
                    projectId: projectId,
                    hasTrackAnalytics: !!trackAnalytics
                  });
                  
                  // Use global deduplication utility
                  if (shouldTrackAnalytics('videoView', userId || projectId, projectId)) {
                    videoViewTrackedRef.current = true;
                    console.log('üìä Tracking video view in AR experience', {
                      userId: userId || projectId,
                      projectId: projectId,
                      videoDuration: videoRef.current?.duration || 0
                    });
                    
                    trackAnalytics('videoView', {
                      source: 'ar_experience',
                      videoProgress: 0,
                      videoDuration: videoRef.current?.duration || 0
                    }).then(() => {
                      console.log('‚úÖ Video view tracked successfully');
                    }).catch(err => {
                      console.error('‚ùå Video view tracking failed:', err);
                      console.error('Error details:', {
                        message: err.message,
                        stack: err.stack,
                        userId: userId || projectId,
                        projectId: projectId
                      });
                      // Mark as failed so it can be retried
                      videoViewTrackedRef.current = false;
                      markAnalyticsFailed('videoView', userId || projectId, projectId);
                    });
                  } else {
                    console.log('‚ÑπÔ∏è Video view already tracked, skipping duplicate');
                    videoViewTrackedRef.current = true; // Still mark as tracked locally
                  }
                } else if (!trackAnalytics) {
                  console.warn('‚ö†Ô∏è trackAnalytics function is not available');
                } else if (videoViewTrackedRef.current) {
                  console.log('‚ÑπÔ∏è Video view already tracked (ref)');
                }
              }).catch(e => {
                // Clear resume flag even on error
                isResuming.current = false;
                console.log(`‚ö†Ô∏è [${timestamp}] Auto-play failed:`, e.message);
                addDebugMessage('üí° Tap the screen to allow video playback', 'info');
              });
            }
            
            // Only log when state CHANGES (not every frame)
            if (!wasTargetVisible) {
              wasTargetVisible = true;
              const timestamp = new Date().toLocaleTimeString();
              console.log(`üéØ [${timestamp}] TARGET DETECTED`);
              addDebugMessage('üéØ Target detected!', 'success');
              setTargetDetected(true);
            }
            
          } else {
            // ‚úÖ Target is lost - hide video mesh AND pause video
            // This matches the working code pattern exactly
            
            // Hide video mesh
            if (videoMeshRef.current && videoMeshRef.current.visible) {
              videoMeshRef.current.visible = false;
              const timestamp = new Date().toLocaleTimeString();
              console.log(`üëÅÔ∏è [${timestamp}] Video mesh hidden`);
            }
            
            // Pause video and save current time for resume
            // Only pause if we haven't already paused in this target-lost cycle
            if (!hasBeenPausedThisCycle) {
              // CRITICAL: Always pause via the texture's video element (most reliable)
              let videoElement = null;
              
              // First, try to get from texture (most reliable source)
              if (videoMeshRef.current && videoMeshRef.current.material && videoMeshRef.current.material.map) {
                const texture = videoMeshRef.current.material.map;
                if (texture.image && texture.image.tagName === 'VIDEO') {
                  videoElement = texture.image;
                  // Restore videoRef if it was lost
                  if (!videoRef.current) {
                    videoRef.current = videoElement;
                    const timestamp = new Date().toLocaleTimeString();
                    console.log(`üîß [${timestamp}] Recovered video ref from texture before pausing`);
                  }
                }
              }
              
              // Fallback to videoRef if texture doesn't have it
              if (!videoElement && videoRef.current) {
                videoElement = videoRef.current;
              }
              
              // Pause the video ONCE if it's playing (this ensures the actual element is paused)
              if (videoElement && !videoElement.paused) {
                // Save current time before pausing
                savedVideoTimeRef.current = videoElement.currentTime;
                videoElement.pause();
                hasBeenPausedThisCycle = true; // Mark as paused to prevent double-pause
                
                // Double-check the pause took effect
                if (videoElement.paused) {
                  const timestamp = new Date().toLocaleTimeString();
                  console.log(`‚è∏Ô∏è [${timestamp}] Video paused successfully (saved time: ${savedVideoTimeRef.current.toFixed(2)}s)`);
                  addDebugMessage(`‚è∏Ô∏è Video paused at ${savedVideoTimeRef.current.toFixed(1)}s`, 'info');
                } else {
                  const timestamp = new Date().toLocaleTimeString();
                  console.warn(`‚ö†Ô∏è [${timestamp}] WARNING: Video pause failed! Forcing pause...`);
                  // Force pause again
                  videoElement.pause();
                  console.log(`‚è∏Ô∏è [${timestamp}] Video force-paused (saved time: ${savedVideoTimeRef.current.toFixed(2)}s)`);
                  addDebugMessage(`‚è∏Ô∏è Video paused at ${savedVideoTimeRef.current.toFixed(1)}s`, 'info');
                }
              }
            }
            
            // Only log when state CHANGES (not every frame)
            if (wasTargetVisible) {
              wasTargetVisible = false;
              // Reset resume flag when target is lost
              isResuming.current = false;
              const timestamp = new Date().toLocaleTimeString();
              console.log(`üîç [${timestamp}] TARGET LOST`);
              addDebugMessage('üîç Target lost', 'warning');
              setTargetDetected(false);
              setVideoPlaying(false);
            }
          }
          
          // No need to call requestAnimationFrame - renderer.setAnimationLoop handles this
        };
        
        // ‚úÖ CRITICAL: Set up our own render loop that includes BOTH rendering AND video control
        // This is exactly how the working code does it
        renderer.setAnimationLoop(() => {
          // Update video control (show/hide mesh, play/pause video)
          animateVideoControl();
          
          // ‚úÖ HIGH QUALITY: Update video texture every frame for smooth playback
          if (videoMeshRef.current && videoRef.current && !videoRef.current.paused) {
            const material = videoMeshRef.current.material;
            if (material && material.map) {
              material.map.needsUpdate = true; // Critical for smooth video frames
            }
          }
          
          // Render the scene (this actually draws everything to the screen)
          renderer.render(scene, camera);
        });
        
        addDebugMessage('üîÑ Combined render + video control loop started', 'success');
        
        // Log MindAR tracking status
        console.log('üîç MindAR tracking info:', {
          maxTrack: mindar.maxTrack,
          anchors: mindar.anchors?.length || 0,
          hasOnTargetFound: typeof mindar.onTargetFound === 'function',
          hasOnTargetLost: typeof mindar.onTargetLost === 'function'
        });
      
      addDebugMessage('üéØ MindAR is now tracking. Point camera at the COMPOSITE IMAGE (with QR code)', 'info');
      addDebugMessage('üí° TIP: Use the image downloaded from Step 5 (Final Design)', 'info');
      
      // Add a test to simulate target detection (for debugging)
      window.testTargetDetection = () => {
        console.log('üß™ Testing target detection manually...');
        if (anchorRef.current) {
          anchorRef.current.visible = true;
          console.log('‚úÖ Manually set anchor.visible = true');
        }
      };
      
      console.log('üß™ Debug: Run window.testTargetDetection() to test video overlay');
      addDebugMessage('üß™ Test command available: window.testTargetDetection()', 'info');
        
      } catch (startError) {
        // Check if it's the buffer corruption error (happens when MindAR tries to process image as .mind file)
        const isBufferError = startError.message && (
          startError.message.includes('Extra') && startError.message.includes('byte') ||
          startError.message.includes('RangeError') ||
          startError.stack?.includes('addImageTargetsFromBuffer')
        );
        
        if (isBufferError) {
          addDebugMessage('‚ùå MindAR failed to start: Target format error', 'error');
          addDebugMessage('üîç Error type: Buffer corruption (image being processed as .mind file)', 'error');
          
          if (targetType === 'image file') {
            addDebugMessage('‚ö†Ô∏è Image files require conversion to .mind format', 'warning');
            addDebugMessage('üí° MindAR cannot reliably process images directly - .mind file required', 'info');
            addDebugMessage('üîß Solution: Generate .mind file from composite image', 'info');
            addDebugMessage('üìã Go back to Step 2: Save QR Position to generate .mind file', 'info');
            
            setError(
              'AR tracking requires a .mind file. ' +
              'The composite image needs to be converted to a .mind file format. ' +
              'Please go back to Step 2: Save QR Position to generate the required .mind file.'
            );
          } else if (targetType === '.mind file') {
            addDebugMessage('‚ö†Ô∏è .mind file appears to be corrupted', 'error');
            addDebugMessage('üí° The .mind file may need to be regenerated', 'info');
            addDebugMessage('üîß Solution: Regenerate .mind file from composite image', 'info');
            
            setError(
              'AR tracking failed: The .mind file appears to be corrupted. ' +
              'Please go back to Step 2: Save QR Position to regenerate the .mind file.'
            );
          } else {
            setError(
              'AR tracking failed: Invalid target format. ' +
              'Please ensure a valid .mind file is generated from your composite image.'
            );
          }
          
          throw startError; // Re-throw to stop initialization
        } else {
          addDebugMessage(`‚ùå MindAR failed to start: ${startError.message}`, 'error');
          addDebugMessage(`üîç Error stack: ${startError.stack?.substring(0, 200)}...`, 'info');
          throw new Error(`MindAR start failed: ${startError.message}`);
        }
      }
      
      // Mark camera as active immediately after start
      setCameraActive(true);
      addDebugMessage('‚úÖ Camera marked as active', 'success');
      
      // Give MindAR a moment to create the canvas and video
      await new Promise(resolve => setTimeout(resolve, 1000));
      
      // Force check for canvas multiple times
      let attempts = 0;
      const maxAttempts = 5;
      let canvas = null;
      
      while (attempts < maxAttempts && !canvas) {
        canvas = containerRef.current?.querySelector('canvas');
        if (!canvas) {
          addDebugMessage(`üîç Canvas check attempt ${attempts + 1}/${maxAttempts} - not found yet`, 'info');
          await new Promise(resolve => setTimeout(resolve, 500));
          attempts++;
        }
      }
      
      // Debug: Check what MindAR created
      addDebugMessage('üîç Checking MindAR elements...', 'info');
      
      const allElements = containerRef.current?.children || [];
      addDebugMessage(`üìä Total children in container: ${allElements.length}`, 'info');
      
      // List all child elements
      Array.from(allElements).forEach((element, index) => {
        addDebugMessage(`üìç Child ${index}: ${element.tagName} (${element.className})`, 'info');
      });
      
      // Check for canvas (reuse the canvas variable from above)
      if (canvas) {
        addDebugMessage(`‚úÖ Canvas found: ${canvas.width}x${canvas.height}`, 'success');
        addDebugMessage(`üìç Canvas position: ${canvas.style.position}`, 'info');
        addDebugMessage(`üìç Canvas z-index: ${canvas.style.zIndex}`, 'info');
        
        // Ensure canvas is visible
        canvas.style.position = 'absolute';
        canvas.style.top = '0';
        canvas.style.left = '0';
        canvas.style.width = '100%';
        canvas.style.height = '100%';
        canvas.style.zIndex = '10'; // Higher z-index to ensure it's visible
        canvas.style.backgroundColor = 'transparent';
        
        // Also ensure the video element is visible and properly configured for mobile
        const video = containerRef.current?.querySelector('video');
        if (video) {
          video.style.position = 'absolute';
          video.style.top = '0';
          video.style.left = '0';
          video.style.width = '100%';
          video.style.height = '100%';
          video.style.zIndex = '5'; // Behind canvas but above background
          video.style.objectFit = 'cover';
          
          // Add mobile-specific attributes if not already set
          if (!video.hasAttribute('playsinline')) {
            video.setAttribute('playsinline', '');
            video.setAttribute('webkit-playsinline', '');
          }
          if (!video.hasAttribute('muted')) {
            video.setAttribute('muted', '');
            video.muted = true;
          }
          video.setAttribute('autoplay', '');
          video.autoplay = true;
          
          addDebugMessage('üîß Video element styling and mobile attributes applied', 'info');
        }
        
        addDebugMessage('üîß Canvas styling applied', 'info');
      } else {
        addDebugMessage('‚ùå No canvas found in container!', 'error');
        
        // Try to find video element
        const video = containerRef.current?.querySelector('video');
        if (video) {
          addDebugMessage(`‚úÖ Video element found: ${video.videoWidth}x${video.videoHeight}`, 'success');
          // Style video element with mobile support
          video.style.position = 'absolute';
          video.style.top = '0';
          video.style.left = '0';
          video.style.width = '100%';
          video.style.height = '100%';
          video.style.zIndex = '1';
          video.style.objectFit = 'cover';
          
          // Add mobile-specific attributes
          video.setAttribute('playsinline', '');
          video.setAttribute('webkit-playsinline', '');
          video.setAttribute('muted', '');
          video.setAttribute('autoplay', '');
          video.muted = true;
          video.autoplay = true;
          
          addDebugMessage('üîß Video element mobile attributes applied', 'info');
        } else {
          addDebugMessage('‚ùå No video element found either!', 'error');
          
          // Check if MindAR created any other elements
          const mindarElements = containerRef.current?.querySelectorAll('[class*="mindar"], [id*="mindar"]');
          if (mindarElements && mindarElements.length > 0) {
            addDebugMessage(`üîç Found ${mindarElements.length} MindAR elements`, 'info');
            mindarElements.forEach((el, i) => {
              addDebugMessage(`üìç MindAR element ${i}: ${el.tagName} (${el.className || el.id})`, 'info');
            });
          } else {
            addDebugMessage('‚ö†Ô∏è MindAR may not have created any visual elements', 'warning');
            addDebugMessage('üîß This could indicate a MindAR configuration issue', 'info');
            
            // Try to manually access the camera stream
            try {
              addDebugMessage('üîß Attempting to access camera stream directly...', 'info');
              
              // Get appropriate camera constraints for this device
              const videoConstraints = getCameraConstraints(false);
              
              const stream = await navigator.mediaDevices.getUserMedia({ 
                video: videoConstraints,
                audio: false
              });
              
              // Create a video element manually
              const video = document.createElement('video');
              video.srcObject = stream;
              video.autoplay = true;
              video.muted = true;
              video.playsInline = true;
              video.setAttribute('playsinline', ''); // iOS requirement
              video.setAttribute('webkit-playsinline', ''); // Older iOS
              video.setAttribute('muted', ''); // Mobile autoplay requirement
              video.style.position = 'absolute';
              video.style.top = '0';
              video.style.left = '0';
              video.style.width = '100%';
              video.style.height = '100%';
              video.style.zIndex = '1';
              video.style.objectFit = 'cover';
              video.style.transform = 'scaleX(-1)'; // Mirror for front camera if needed
              
              // Ensure video plays on mobile
              video.addEventListener('loadedmetadata', () => {
                video.play().catch(err => {
                  addDebugMessage(`‚ö†Ô∏è Video autoplay failed: ${err.message}`, 'warning');
                });
              });
              
              containerRef.current.appendChild(video);
              addDebugMessage('‚úÖ Manual video element created and added', 'success');
              
            } catch (streamError) {
              addDebugMessage(`‚ùå Failed to create manual video: ${streamError.message}`, 'error');
            }
          }
        }
      }
      
      // Check container dimensions
      const containerRect = containerRef.current?.getBoundingClientRect();
      if (containerRect) {
        addDebugMessage(`üìç Container dimensions: ${containerRect.width}x${containerRect.height}`, 'info');
      }
      
      // Ensure camera is active and AR is ready
      setCameraActive(true);
      setArReady(true);
      setIsInitialized(true);
      
      // Expose debug helpers
      window.debugAR = {
        showVideoMesh: () => {
          if (videoMeshRef.current) {
            videoMeshRef.current.visible = true;
            console.log('‚úÖ Video mesh manually shown');
            return 'Video mesh is now visible';
          }
          return 'Video mesh not available';
        },
        hideVideoMesh: () => {
          if (videoMeshRef.current) {
            videoMeshRef.current.visible = false;
            console.log('‚úÖ Video mesh manually hidden');
            return 'Video mesh is now hidden';
          }
          return 'Video mesh not available';
        },
        playVideo: async () => {
          if (videoRef.current) {
            try {
              await videoRef.current.play();
              console.log('‚úÖ Video manually started');
              return 'Video playing';
            } catch (err) {
              console.error('‚ùå Video play failed:', err);
              return `Error: ${err.message}`;
            }
          }
          return 'Video not available';
        },
        getVideoMeshInfo: () => {
          if (videoMeshRef.current) {
            return {
              visible: videoMeshRef.current.visible,
              position: videoMeshRef.current.position,
              renderOrder: videoMeshRef.current.renderOrder,
              material: {
                opacity: videoMeshRef.current.material.opacity,
                transparent: videoMeshRef.current.material.transparent,
                depthTest: videoMeshRef.current.material.depthTest,
                depthWrite: videoMeshRef.current.material.depthWrite
              }
            };
          }
          return 'Video mesh not available';
        },
        getAnchorInfo: () => {
          if (anchorRef.current) {
            return {
              visible: anchorRef.current.group.visible,
              children: anchorRef.current.group.children.length,
              position: anchorRef.current.group.position
            };
          }
          return 'Anchor not available';
        }
      };
      
      console.log('üõ†Ô∏è Debug helpers available: window.debugAR');
      addDebugMessage('üõ†Ô∏è Debug helpers: window.debugAR.showVideoMesh(), window.debugAR.playVideo()', 'info');
      
      // On mobile, if we still don't have a visible video element, force create one
      const isMobile = isMobileDevice();
      if (isMobile) {
        addDebugMessage('üì± Mobile device detected - verifying video visibility...', 'info');
        
        // Wait a bit more for MindAR to fully initialize
        await new Promise(resolve => setTimeout(resolve, 1000));
        
        // Check for ALL video elements
        const allVideos = containerRef.current?.querySelectorAll('video');
        addDebugMessage(`üîç Found ${allVideos?.length || 0} video element(s) in container`, 'info');
        
        if (allVideos && allVideos.length > 0) {
          Array.from(allVideos).forEach((vid, index) => {
            addDebugMessage(`üìπ Video ${index}: ${vid.videoWidth}x${vid.videoHeight}, paused=${vid.paused}, srcObject=${!!vid.srcObject}`, 'info');
          });
        }
        
        const video = containerRef.current?.querySelector('video');
        if (!video) {
          addDebugMessage('‚ö†Ô∏è No video element found on mobile - creating manual stream...', 'warning');
          
          try {
            // Get camera stream again
            const videoConstraints = getCameraConstraints(false);
            const stream = await navigator.mediaDevices.getUserMedia({ 
              video: videoConstraints,
              audio: false
            });
            
            // Create video element manually
            const manualVideo = document.createElement('video');
            manualVideo.srcObject = stream;
            manualVideo.autoplay = true;
            manualVideo.muted = true;
            manualVideo.playsInline = true;
            manualVideo.setAttribute('playsinline', '');
            manualVideo.setAttribute('webkit-playsinline', '');
            manualVideo.setAttribute('muted', '');
            manualVideo.setAttribute('autoplay', '');
            
            // Style for full visibility
            manualVideo.style.position = 'absolute';
            manualVideo.style.top = '0';
            manualVideo.style.left = '0';
            manualVideo.style.width = '100%';
            manualVideo.style.height = '100%';
            manualVideo.style.objectFit = 'cover';
            manualVideo.style.zIndex = '1';
            
            // Add to container
            containerRef.current.insertBefore(manualVideo, containerRef.current.firstChild);
            
            // Force play
            await manualVideo.play().catch(err => {
              addDebugMessage(`‚ö†Ô∏è Manual video play failed: ${err.message}`, 'warning');
            });
            
            addDebugMessage('‚úÖ Manual video stream created and playing', 'success');
          } catch (streamError) {
            addDebugMessage(`‚ùå Failed to create manual video stream: ${streamError.message}`, 'error');
          }
        } else {
          // Video exists, ensure it's visible and playing
          addDebugMessage('‚úÖ Video element found - ensuring visibility...', 'success');
          
          // Log current video state before modifications
          addDebugMessage(`üìπ Video current state: width=${video.videoWidth}, height=${video.videoHeight}, paused=${video.paused}, srcObject=${!!video.srcObject}`, 'info');
          addDebugMessage(`üìπ Video style: display=${video.style.display}, visibility=${video.style.visibility}, opacity=${video.style.opacity}`, 'info');
          
          video.style.position = 'absolute';
          video.style.top = '0';
          video.style.left = '0';
          video.style.width = '100%';
          video.style.height = '100%';
          video.style.objectFit = 'cover';
          video.style.zIndex = '1';
          video.style.display = 'block';
          video.style.visibility = 'visible';
          video.style.opacity = '1';
          
          // Ensure mobile attributes are set
          video.setAttribute('playsinline', '');
          video.setAttribute('webkit-playsinline', '');
          video.setAttribute('muted', '');
          video.setAttribute('autoplay', '');
          video.muted = true;
          video.autoplay = true;
          
          // Check if video has a stream
          if (!video.srcObject) {
            addDebugMessage('‚ö†Ô∏è Video element has no srcObject - may not have camera stream!', 'warning');
          }
          
          // Force play
          if (video.paused) {
            addDebugMessage('üé¨ Video is paused, attempting to play...', 'info');
            try {
              await video.play();
              addDebugMessage('‚úÖ Video play succeeded', 'success');
            } catch (err) {
              addDebugMessage(`‚ùå Video play failed: ${err.message}`, 'error');
            }
          } else {
            addDebugMessage('‚úÖ Video is already playing', 'success');
          }
          
          // Log final state
          addDebugMessage(`üìπ Video final state: ${video.videoWidth}x${video.videoHeight}, paused: ${video.paused}, readyState: ${video.readyState}`, 'info');
        }
      }
      
      return true;

    } catch (error) {
      addDebugMessage(`‚ùå MindAR initialization failed: ${error.message}`, 'error');
      setError(`AR initialization failed: ${error.message}`);
      return false;
    }
  }, [librariesLoaded, projectData, isInitialized, addDebugMessage, setError, setCameraActive, setArReady, setIsInitialized, setTargetDetected, setVideoPlaying, setupVideo]);

  // Start AR scanning
  const startScanning = useCallback(async () => {
    if (isScanning || !isInitialized) return;

    try {
      addDebugMessage('üì± Starting AR scan...', 'info');
      setIsScanning(true);
      setError(null);

      // MindAR is already started during initialization, just set scanning state
      addDebugMessage('‚úÖ AR scanning active', 'success');

    } catch (error) {
      addDebugMessage(`‚ùå Failed to start scanning: ${error.message}`, 'error');
      setError(`Failed to start scanning: ${error.message}`);
      setIsScanning(false);
    }
  }, [isScanning, isInitialized, setIsScanning, setError, addDebugMessage]);

  // Stop AR scanning
  const stopScanning = useCallback(async () => {
    if (!isScanning) return;

    try {
      addDebugMessage('‚èπÔ∏è Stopping AR scan...', 'info');
      
      if (mindarRef.current) {
        await mindarRef.current.stop();
      }
      
      setIsScanning(false);
      setCameraActive(false);
      setTargetDetected(false);
      setVideoPlaying(false);
      
      addDebugMessage('‚úÖ AR scanning stopped', 'success');

    } catch (error) {
      addDebugMessage(`‚ùå Failed to stop scanning: ${error.message}`, 'error');
    }
  }, [isScanning, setIsScanning, setCameraActive, setTargetDetected, setVideoPlaying, addDebugMessage]);

  // Toggle video playback
  const toggleVideo = useCallback(async () => {
    if (!videoRef.current || !targetDetected) return;

    try {
      if (videoPlaying) {
        videoRef.current.pause();
        setVideoPlaying(false); // Use direct setter for immediate response
        addDebugMessage('‚è∏Ô∏è Video paused by user', 'info');
      } else {
        const playPromise = videoRef.current.play();

        if (playPromise !== undefined) {
          try {
            await playPromise;
            setVideoPlaying(true); // Use direct setter for immediate response
            addDebugMessage('‚ñ∂Ô∏è Video started by user', 'success');
          } catch (playError) {
            if (playError.name === 'NotAllowedError') {
              addDebugMessage('‚ö†Ô∏è Autoplay blocked, trying with muted...', 'warning');
              videoRef.current.muted = true;
              try {
                await videoRef.current.play();
                setVideoPlaying(true); // Use direct setter for immediate response
                addDebugMessage('‚ñ∂Ô∏è Video started with muted fallback', 'success');
              } catch (mutedError) {
                addDebugMessage(`‚ùå Video play failed even with muted: ${mutedError.message}`, 'error');
                throw mutedError;
              }
            } else {
              addDebugMessage(`‚ùå Video play failed: ${playError.message}`, 'error');
              throw playError;
            }
          }
        }
      }
    } catch (error) {
      addDebugMessage(`‚ùå Video toggle failed: ${error.message}`, 'error');
    }
  }, [videoPlaying, targetDetected, setVideoPlaying, addDebugMessage]);

  // Toggle video mute
  const toggleMute = useCallback(() => {
    if (!videoRef.current) return;

    videoRef.current.muted = !videoRef.current.muted;
    // Update the videoMuted state in the parent component
    safeSetVideoMuted(videoRef.current.muted);
    addDebugMessage(`üîä Video ${videoRef.current.muted ? 'muted' : 'unmuted'}`, 'info');
  }, [addDebugMessage, safeSetVideoMuted]);

  // Cleanup function
  const cleanupAR = useCallback(async () => {
    addDebugMessage('üßπ Cleaning up AR resources...', 'info');
    
    try {
      // Stop MindAR first
      if (mindarRef.current) {
        await mindarRef.current.stop();
        mindarRef.current = null;
      }
      
      // Clean up video
      if (videoRef.current) {
        videoRef.current.pause();
        videoRef.current.src = '';
        videoRef.current.load();
        videoRef.current = null;
      }
      
      // Clean up video mesh
      if (videoMeshRef.current) {
        try {
          if (videoMeshRef.current.material && videoMeshRef.current.material.map) {
            videoMeshRef.current.material.map.dispose();
          }
          
          if (videoMeshRef.current.material) {
            videoMeshRef.current.material.dispose();
          }
          
          if (sceneRef.current && videoMeshRef.current.parent) {
            sceneRef.current.remove(videoMeshRef.current);
          }
          
          if (videoMeshRef.current.geometry) {
            videoMeshRef.current.geometry.dispose();
          }
        } catch (error) {
          console.warn('Error disposing video mesh:', error);
        }
        videoMeshRef.current = null;
      }
      
      // Clean up renderer and WebGL context
      if (rendererRef.current) {
        try {
          // Dispose of the renderer to free WebGL context
          rendererRef.current.dispose();
          // Clear the canvas
          const canvas = rendererRef.current.domElement;
          if (canvas && canvas.parentNode) {
            canvas.parentNode.removeChild(canvas);
          }
        } catch (error) {
          console.warn('Error disposing renderer:', error);
        }
        rendererRef.current = null;
      }
      
      // Clean up blob URL if it exists
      if (blobURLRef.current) {
        URL.revokeObjectURL(blobURLRef.current);
        addDebugMessage('üóëÔ∏è Blob URL revoked', 'info');
        blobURLRef.current = null;
      }
      
      // Clear other refs
      sceneRef.current = null;
      cameraRef.current = null;
      anchorRef.current = null;
      
      addDebugMessage('‚úÖ AR cleanup completed', 'info');
    } catch (error) {
      addDebugMessage(`‚ùå Cleanup error: ${error.message}`, 'error');
    }
  }, [addDebugMessage]);

  // Restart AR
  const restartAR = useCallback(async () => {
    addDebugMessage('üîÑ Restarting AR...', 'info');
    
    await stopScanning();
    await cleanupAR();
    resetARState();

    setTimeout(async () => {
      const success = await initializeMindAR();
      if (success) {
        await startScanning();
      }
    }, 1000);
  }, [stopScanning, cleanupAR, resetARState, initializeMindAR, startScanning, addDebugMessage]);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      cleanupAR();
    };
  }, [cleanupAR]);

  return {
    // Refs
    containerRef,
    videoRef,
    mindarRef,
    sceneRef,
    rendererRef,
    cameraRef,
    anchorRef,
    videoMeshRef,
    
    // Functions
    initializeMindAR,
    startScanning,
    stopScanning,
    toggleVideo,
    toggleMute,
    restartAR,
    cleanupAR
  };
};
